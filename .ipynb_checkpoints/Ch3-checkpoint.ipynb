{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (p.51) Ch3. Deep Learning for Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (p.53) Deep Learning Applications in Computer Vision\n",
    "- Classification\n",
    "- Detection and Localization\n",
    "- (Semantic) Segmentation\n",
    "- Similarity Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (p.55) Image Captioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (p.56) Generative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (p.57) Video Analyisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (p.57) Neural Networks at Their Core\n",
    "- Artificial Neural Networks (ANN)\n",
    "- Artificial Neurons or Perceptrons\n",
    "Activation functions: Sigmoid, tanh, Rectified linear unit(ReLU)\n",
    "- Training Neural Networks: backpropagation, gradient descent and stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (p.63) Convolutional Neural Networks (CNN)\n",
    "CNNs have three types of layer\n",
    "- Convolution Layer\n",
    "The convolution is done by applying a filter or kernel that helps form a feature map.\n",
    "- Pooling Layer\n",
    "responsible for reducing the dimensionality and thus reducing the parameter count to control the training timing and avoid overfitting\n",
    "- Fully Connected Layer\n",
    "After the convolution and pooling, the final feature map used for the “classification” task is executed by the fully connected layer.\n",
    "\n",
    "In CNNs, the layers are set as three dimensions: height, width, and depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (p.66) Recurrent Neural Networks (RNN)\n",
    "The key differentiating factor for RNN is that it can remember the input because it has internal memory. RNN is considered to be one of the most robust neural network algorithms. This is a relatively old algorithm but is becoming more popular in recent years because of the invention of long short-term memory (LSTM).\n",
    "\n",
    "- Backpropagation Through Time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
