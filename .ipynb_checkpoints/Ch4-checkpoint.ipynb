{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (p.71) Ch.4 Image Manipulation and Segmentation\n",
    "As part of image manipulations, the chapter will provide a step-by-step guide on how to perform transformations on images such as translations, rotations, resizing, blurring, sharpening, edge detection, masking, converting a photograph into a sketch, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Manipulations\n",
    "Overall, image manipulation refers to a process of altering or modifying an image for different purposes such as beautifying images, sharpening images with noise, restoring old black-and-white images and re-creating them in color, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (p.73) Accessing and Manipulating Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the flower image and load it into a variable flower_image\n",
    "flower_image = cv2.imread(\"./images/flower_pink.jpg\")\n",
    "type(flower_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[219  68 231]\n"
     ]
    }
   ],
   "source": [
    "#access a specific pixel using the coordinate based access from the matrix\n",
    "pixel=flower_image[200,250]\n",
    "\n",
    "#see what color space this pixel represents - this is an RBG representation\n",
    "print(pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets change the pixel color value to blue\n",
    "flower_image[200,250]=(255,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets change the pixel color value to blue in a region range as against\n",
    "flower_image[200:250,200:350]=(0,255,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('modified pixel', flower_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (p.75) Drawing Geometric Shapes or Writing Text on a Color Image\n",
    "In this section, you will explore a few geometric functions in OpenCV. You can use the line(), rectangle(), circle(), ellipse(), polygon(), or putText() functions in OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.line()\n",
    "To draw a line, this function takes the\n",
    "following arguments:\n",
    "- Image object on which the line needs to be drawn\n",
    "- Starting point’s pixel coordinates\n",
    "- Ending point’s pixel coordinates\n",
    "- Color in BGR (not RGB) format\n",
    "- Thickness (in pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.rectangle()\n",
    "To draw a square or rectangle, similar to the line() function, this function takes the following arguments:\n",
    "- Image object on which the rectangle needs to be drawn\n",
    "- Pixel coordinates of the vertex at the top left\n",
    "- Pixel coordinates of the lower-right vertex\n",
    "- Color in BGR (not RGB)\n",
    "- Thickness (in pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.circle()\n",
    "To draw a circle, this function takes the following arguments:\n",
    "- Image object on which the circle needs to be drawn\n",
    "- Center pixel’s coordinates\n",
    "- Pixel radius of the circle\n",
    "- Color in BGR (not RGB)\n",
    "- Thickness (in pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.ellipse()\n",
    "To draw a ellipse, this function takes the following arguments:\n",
    "- Image object on which the ellipse needs to be drawn\n",
    "- Center pixel’s coordinates\n",
    "- Length of the minor and major axes\n",
    "- Rotation angle of the ellipse (calculated counterclockwise)\n",
    "- Starting angle (calculated clockwise)\n",
    "- Final angle (calculated clockwise)\n",
    "- Color in BGR (not RGB—be careful)\n",
    "- Thickness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.polyline()\n",
    "To draw a polygon, this function takes the following arguments:\n",
    "- Image object on which the polygon needs to be drawn\n",
    "- The image object on which to draw\n",
    "- The array of coordinates\n",
    "- True, if it is a closed line\n",
    "- Color\n",
    "- Thickness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.putText()\n",
    "To write text, this function takes the following arguments:\n",
    "- The image on which the text is to be written\n",
    "- The text to be written\n",
    "- Coordinates of the text’s starting point\n",
    "- Font to be used\n",
    "- Font size\n",
    "- Text color\n",
    "- Text thickness\n",
    "- The type of line used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the flower image and load it into a variable flower_image\n",
    "flower_image=cv2.imread(\"./images/flower_pink.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.line(flower_image,(25,21),(100,100),(255,0,0),5) # image, point1, point2, BGR, thickness\n",
    "cv2.rectangle(flower_image,(25,21),(200,200),(0,255,0),2)\n",
    "cv2.circle(flower_image,(50,50),50,(0,0,255),1) # image,center, radius, BGR, thickness\n",
    "\n",
    "cv2.imshow(\"Geometry\", flower_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (p.79) Filtering Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2.medianBlue(src, ksize[, dst]): This function smoothens an image using the median filter with the \"ksize X ksize\" aperture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the flower image and load it into a variable image\n",
    "image=cv2.imread(\"./images/flower_noise.jpg\")\n",
    "\n",
    "#kernel value of 3 3x3 matrix neighbourhood is used\n",
    "noisereduced_version1 = cv2.medianBlur(image,7)\n",
    "noisereduced_version2 = cv2.medianBlur(noisereduced_version1,7)\n",
    "\n",
    "cv2.imshow(\"Original\",image)\n",
    "cv2.imshow(\"Corrected1\",noisereduced_version1)\n",
    "cv2.imshow(\"Corrected2\",noisereduced_version2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (p.82) Tranforming Images\n",
    "- Affine transformations: scaling, rotation, translation\n",
    "- Nonaffine transformation: (non-orthogonal transformation) ex) rectangular > rectilinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Translation\n",
    "\n",
    "image = cv2.imread(\"./images/pup.jpg\")\n",
    "num_rows, num_cols = image.shape[:2]\n",
    "\n",
    "translation_matrix = np.float32([ [1,0,70], [0,1,110] ])\n",
    "image_translation = cv2.warpAffine(image, translation_matrix, (num_cols, num_rows))\n",
    "cv2.imshow('Translation', image_translation)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rotation - Code not working\n",
    "\n",
    "image = cv2.imread(\"./images/pup.jpg\")\n",
    "num_rows, num_cols = image.shape[:2]\n",
    "\n",
    "translation_matrix = np.float32([ [1,0,int(0.5*num_cols)],[0,1,int(0.5*num_rows)] ])\n",
    "rotation_matrix = cv2.getRotationMatrix2D((num_cols, num_rows), 30, 1.0)\n",
    "\n",
    "image_translation = cv2.warpAffine(image, translation_matrix, (2*num_cols, 2*num_rows))\n",
    "image_rotation = cv2.warpAffine(image_translation, rotation_matrix, (2*num_cols, 2*num_rows))\n",
    "\n",
    "cv2.imshow('Rotation', image_rotation)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image scaling\n",
    "\n",
    "img = cv2.imread(\"./images/pup.jpg\")\n",
    "\n",
    "img_scaled = cv2.resize(img,None,fx=1.2, fy=1.2, interpolation = cv2.INTER_LINEAR)\n",
    "cv2.imshow('Scaling - Linear Interpolation', img_scaled)\n",
    "\n",
    "img_scaled = cv2.resize(img,None,fx=1.2, fy=1.2,interpolation = cv2.INTER_CUBIC)\n",
    "cv2.imshow('Scaling - Cubic Interpolation', img_scaled)\n",
    "\n",
    "img_scaled = cv2.resize(img,(450, 400), interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow('Scaling - Skewed Size', img_scaled)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Edge detection\n",
    "\n",
    "frame = cv2.imread('./images/dolphin.jpg')\n",
    "hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "lower_red = np.array([30,150,50])\n",
    "upper_red = np.array([255,255,180])\n",
    "\n",
    "mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "\n",
    "cv2.imshow('Original',frame)\n",
    "\n",
    "edges = cv2.Canny(frame,100,200)\n",
    "cv2.imshow('Edges',edges)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of contours found = 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Image Segmentation\n",
    "image = cv2.imread('images/bunchofshapes.png')\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find Canny edges\n",
    "edged = cv2.Canny(gray, 50, 200)\n",
    "cv2.imshow('1 - Canny Edges', edged)\n",
    "\n",
    "\n",
    "# Find contours and print how many were found\n",
    "contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[-2:]\n",
    "print(\"Number of contours found =\", len(contours))\n",
    "\n",
    "# Draw all contours\n",
    "blank_image = 255 * np.ones(shape=[262, 932, 3], dtype=np.uint8)\n",
    "cv2.drawContours(blank_image, contours, -1, (0,255,0), 3)\n",
    "cv2.imshow('2 - All contours over blank image', blank_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
